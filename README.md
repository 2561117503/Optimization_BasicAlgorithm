# Optimization Basic Algorithm
## Introduction: 
### Save my optimization code demo: convex optimization; numerical optimization algorithm<br>

note: all code based on cvxpy package

## Project struct
> Linear Search Methods: 
>> Steepest Descent Method <br>
>> Newton Method<br> 
>> Quasi-Newton Method<br> 
>> Conjugate Gradient Method<br> 
>> Matrix Util Method<br> 

## Algorithm list
### Linear Search Methods :
> StepLength:
>> { Backtracking Line Search } Algorithm: [BacktrackingLineSearch.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepSize/BacktrackingLineSearch.py) <br>
>> { Interpolation} Algorithm: [Interpolation.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepSize/Interpolation.py) <br>
>> { Zoom} Algorithm: [Zoom.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepSize/Zoom.py) <br>
>> { WolfeLineSearch} Algorithm: [WolfeLineSearch.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepSize/WolfeLineSearch.py) <br>

> SteepestDescent
>> { Gradient Descent Method  } Algorithm: [GradientDescentMethod.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/SteepestDescent/GradientDescentMethod.py) <br>

> Newton
>> { Newton Method  } Algorithm: [NewtonMethod.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/Newton/NewtonMethod.py) <br>

> Quasi-Newton

> ConjugateGradient

> MatrixUtil
>> { Cholesky Factorization: LDL^T} Algorithm: [Cholesky_LDL.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/MatrixUtil/Cholesky_LDL.py) <br>

## References
> Stephen Boyd and Lieven vandenberghe: `Convex optimization` <br>

> Jorge Nocedal and Stephen J.Wright : `Numerical optimization`  Second Edition
