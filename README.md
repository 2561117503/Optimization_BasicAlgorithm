# Optimization Basic Algorithm
## Introduction: 
### Save my optimization code demo: convex optimization; numerical optimization algorithm<br>

note: all code based on cvxpy package

## Project struct
> Linear Search Methods: 
>> Steepest Descent Method <br>
>> Newton Method<br> 
>> Quasi-Newton Method<br> 
>> Conjugate Gradient Method<br> 
>> Matrix Util Method<br> 

## Algorithm list:
### Linear Search Methods :
> { Backtracking Line Search } Algorithm: [BacktrackingLineSearch.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepLength/BacktrackingLineSearch.py) <br>
> { Interpolation} Algorithm: [Interpolation.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/StepLength/Zoom.py) <br>
> { Gradient Descent Method  } Algorithm: [GradientDescentMethod.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/SteepestDescent/GradientDescentMethod.py) <br>
> { Newton Method  } Algorithm: [NewtonMethod.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/Newton/NewtonMethod.py) <br>
> { Cholesky Factorization: LDL^T} Algorithm: [Cholesky_LDL.py](https://github.com/YEN-GitHub/Optimization_BasicAlgorithm/tree/master/LinearSearchMethods/MatrixUtil/Cholesky_LDL.py) <br>

## References
> Stephen Boyd and Lieven vandenberghe: `Convex optimization` <br>

> Jorge Nocedal and Stephen J.Wright : `Numerical optimization`  Second Edition
